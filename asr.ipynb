{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple speech recognition system can be implemented using DTW + MFCC.\n",
    "based on: https://github.com/pierre-rouanet/dtw/blob/master/examples/speech-recognition.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.fftpack import dct\n",
    "from scipy.signal import get_window\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import python_speech_features\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [data-speech-commands database](https://storage.cloud.google.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz) composed of 105,000 WAVE audio files of people saying thirty different words. We will use only a subset of this database.\n",
    "\n",
    "We assume that you have previously downloaded and extracted the database. You need to specify the path to the folder where you extracted it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_PATH = '/home/joao/Desktop/datasets/data_speech_commands_v0.02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'cat', 'dog', 'happy', 'house', 'zero'}"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "labels = {'cat', 'dog', 'house', 'happy', 'zero'}\n",
    "labels"
   ]
  },
  {
   "source": [
    "## Define MFCC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_mfcc(audio, sr, n_fft=2048, hop_length=512, n_mels=128, num_ceps=13, cep_lifter=22):\n",
    "    ##### Getting melspectrogram #####\n",
    "    fft_windows = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length)\n",
    "    magnitude = np.abs(fft_windows)**2\n",
    "    mel_filter_banks = librosa.filters.mel(sr=sr, n_fft=n_fft, n_mels=n_mels)\n",
    "    melspectrogram = mel_filter_banks.dot(magnitude)\n",
    "    ##### Getting the MFCC #####\n",
    "    melspectrogram_db = librosa.power_to_db(melspectrogram)\n",
    "    mfcc = dct(melspectrogram_db, type=2, axis=0, norm='ortho')[:num_ceps]\n",
    "    if cep_lifter > 0:\n",
    "        nframes,ncoeff = np.shape(mfcc)\n",
    "        n = np.arange(ncoeff)\n",
    "        cep_lifter = 1 + (cep_lifter/2.)*np.sin(np.pi*n/cep_lifter)\n",
    "        mfcc = cep_lifter*mfcc \n",
    "        return mfcc\n",
    "    elif cep_lifter == 0:\n",
    "        return mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precompute all MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use only N occurences per word\n",
    "N = 25\n",
    "\n",
    "mfccs = []\n",
    "true_labels = []\n",
    "\n",
    "for l in labels:\n",
    "    # Take N pronounciations from a class, randomly\n",
    "    sounds = glob.glob(os.path.join(DATABASE_PATH, l, '*.wav'))\n",
    "    np.random.shuffle(sounds)\n",
    "    sounds = sounds[:N]\n",
    "\n",
    "    for s in sounds:    \n",
    "        y, sr = librosa.load(s, sr=None)\n",
    "        # mfcc = alt_mfcc(y, sr, num_ceps=20, cep_lifter=22)\n",
    "        # mfcc = librosa.feature.mfcc(y, sr, n_mfcc=13, lifter=22)\n",
    "        # Calculate the MFCC of the sample and determine their label (ex: That MFCC corresponds to 'cat')\n",
    "        mfcc = alt_mfcc(y, sr, num_ceps=16, cep_lifter=22)\n",
    "        mfccs.append(mfcc.T)\n",
    "        true_labels.append(l)\n",
    "        \n",
    "mfccs = np.array(mfccs)\n",
    "true_labels = np.array(true_labels)\n"
   ]
  },
  {
   "source": [
    "## Sanity check for the MFCC implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alt_mfcc liftering process differs from the librosa\n",
    "a = alt_mfcc(y, sr, num_ceps=16, cep_lifter=0)\n",
    "b = librosa.feature.mfcc(y,sr, n_mfcc=16, lifter=0)\n",
    "# If assert is true, then do nothing, if false, display error\n",
    "assert (a == b).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train/val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine validation set percentage\n",
    "val_percent = 0.2\n",
    "# Get val_percent from all dataset\n",
    "n_val = int(val_percent * len(true_labels))\n",
    "# Shuffles the labels\n",
    "I = np.random.permutation(len(true_labels))\n",
    "# Divides the labels into validation and train sets\n",
    "I_val, I_train = I[:n_val], I[n_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition system with DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtw import dtw\n",
    "\n",
    "def cross_validation(train_indices, val_indices):\n",
    "    score = 0.0\n",
    "    # For each sample in the validation set, it will be determined a sample from the train set with the minimum distance \n",
    "    for i in val_indices:\n",
    "        x = mfccs[i]\n",
    "        dmin, jmin = np.inf, -1\n",
    "        for j in train_indices:\n",
    "            y = mfccs[j]\n",
    "            # Returns the minimum distance between the validation and train sample (uses euclidean distance in 'dist')\n",
    "            d, _, _, _ = dtw(x, y, dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "            # If the minimum distance from DTW is inferior to infinite (or the previous distance),\n",
    "            # then updates the most similar sample (updating the minimum distance) and gets it index (jmin) as well\n",
    "            if d < dmin:\n",
    "                dmin = d\n",
    "                jmin = j\n",
    "        # If the sample with the biggest similarity (minimum distance) with the validation sample is also similar to it,\n",
    "        # then the system correctly recognized the word by checking MFCC similarity, increasing one point in the recognition \n",
    "        # score\n",
    "        score += 1.0 if (true_labels[i] == true_labels[jmin]) else 0.0\n",
    "    return score / len(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recognition rate 64.0%\n"
     ]
    }
   ],
   "source": [
    "rec_rate = cross_validation(I_train, I_val)\n",
    "print('Recognition rate {}%'.format(100. * rec_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "16ce07b1-20d0-47a5-9f64-e3fa59a98225"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}