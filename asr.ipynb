{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple speech recognition system can be implemented using DTW + MFCC.\n",
    "based on: https://github.com/pierre-rouanet/dtw/blob/master/examples/speech-recognition.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.fftpack import dct\n",
    "from scipy.signal import get_window\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import python_speech_features\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [data-speech-commands database](https://storage.cloud.google.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz) composed of 105,000 WAVE audio files of people saying thirty different words. We will use only a subset of this database.\n",
    "\n",
    "We assume that you have previously downloaded and extracted the database. You need to specify the path to the folder where you extracted it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_PATH = '/home/joao/Desktop/datasets/data_speech_commands_v0.02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'cat', 'dog', 'happy', 'house', 'zero'}"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "labels = {'cat', 'dog', 'house', 'happy', 'zero'}\n",
    "labels"
   ]
  },
  {
   "source": [
    "## Define MFCC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alt_mfcc(audio, sr, n_fft=2048, hop_length=512, n_mels=128, num_ceps=13, cep_lifter=22):\n",
    "    ##### Getting melspectrogram #####\n",
    "    fft_windows = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length)\n",
    "    magnitude = np.abs(fft_windows)**2\n",
    "    mel_filter_banks = librosa.filters.mel(sr=sr, n_fft=n_fft, n_mels=n_mels)\n",
    "    melspectrogram = mel_filter_banks.dot(magnitude)\n",
    "    ##### Getting the MFCC #####\n",
    "    melspectrogram_db = librosa.power_to_db(melspectrogram)\n",
    "    mfcc = dct(melspectrogram_db, type=2, axis=0, norm='ortho')[:num_ceps]\n",
    "    if cep_lifter > 0:\n",
    "        nframes,ncoeff = np.shape(mfcc)\n",
    "        n = np.arange(ncoeff)\n",
    "        cep_lifter = 1 + (cep_lifter/2.)*np.sin(np.pi*n/cep_lifter)\n",
    "        mfcc = cep_lifter*mfcc \n",
    "        # mfcc *= (1 + (cep_lifter / 2)* np.sin(np.pi * np.arange(1, 1 + n_mels, dtype=mfcc.dtype) / cep_lifter)[:, np.newaxis])\n",
    "        return mfcc\n",
    "    elif cep_lifter == 0:\n",
    "        return mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precompute all MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use only N occurences per word\n",
    "N = 25\n",
    "\n",
    "mfccs = []\n",
    "true_labels = []\n",
    "\n",
    "for l in labels:\n",
    "    sounds = glob.glob(os.path.join(DATABASE_PATH, l, '*.wav'))\n",
    "    np.random.shuffle(sounds)\n",
    "    sounds = sounds[:N]\n",
    "\n",
    "    for s in sounds:    \n",
    "        y, sr = librosa.load(s)\n",
    "        mfcc = alt_mfcc(y, sr, num_ceps=13, cep_lifter=22)\n",
    "        # mfcc = librosa.feature.mfcc(y, sr, n_mfcc=13, lifter=22)\n",
    "        mfccs.append(mfcc.T)\n",
    "        true_labels.append(l)\n",
    "        \n",
    "mfccs = np.array(mfccs)\n",
    "true_labels = np.array(true_labels)\n"
   ]
  },
  {
   "source": [
    "## Optional test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = alt_mfcc(y, sr, num_ceps=20, cep_lifter=0)\n",
    "# b = librosa.feature.mfcc(y,sr, n_mfcc=20, lifter=0)\n",
    "# assert (a == b).all()\n",
    "\n",
    "# plt.figure(figsize=(25, 10))\n",
    "# librosa.display.specshow(b, \n",
    "#                          x_axis=\"time\", \n",
    "#                          sr=sr)\n",
    "# plt.colorbar(format=\"%+2.f\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train/val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_percent = 0.2\n",
    "n_val = int(val_percent * len(true_labels))\n",
    "\n",
    "I = np.random.permutation(len(true_labels))\n",
    "I_val, I_train = I[:n_val], I[n_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave P Out Cross Validation with DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dtw import dtw\n",
    "\n",
    "def cross_validation(train_indices, val_indices):\n",
    "    score = 0.0\n",
    "\n",
    "    for i in val_indices:\n",
    "        x = mfccs[i]\n",
    "\n",
    "        dmin, jmin = np.inf, -1\n",
    "        for j in train_indices:\n",
    "            y = mfccs[j]\n",
    "            d, _, _, _ = dtw(x, y, dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "\n",
    "            if d < dmin:\n",
    "                dmin = d\n",
    "                jmin = j\n",
    "\n",
    "        score += 1.0 if (true_labels[i] == true_labels[jmin]) else 0.0\n",
    "        \n",
    "    return score / len(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recognition rate 60.0%\n"
     ]
    }
   ],
   "source": [
    "rec_rate = cross_validation(I_train, I_val)\n",
    "print('Recognition rate {}%'.format(100. * rec_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "16ce07b1-20d0-47a5-9f64-e3fa59a98225"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}